{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program is the implementation of the K-Fold Cross Validation of Machine Learning and Deep Learning Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model_evaluation_utils as meu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load and merge datasets # white = control; red = stroke; wine = data\n",
    "No_Concussion = pd.read_csv('Healthy Participants Data.csv', delim_whitespace=False)\n",
    "Yes_Concussion = pd.read_csv('Injured Participants Data.csv', delim_whitespace=False)\n",
    "\n",
    "# store wine type as an attribute\n",
    "No_Concussion['data_type'] = 'NoConcussion'   \n",
    "Yes_Concussion['data_type'] = 'Concussion'\n",
    "\n",
    "# merge control and stroke data\n",
    "datas = pd.concat([No_Concussion, Yes_Concussion])\n",
    "#datas = datas.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Prepare Training and Testing Datasets\n",
    "stp_features = datas.iloc[:,:-1]\n",
    "stp_feature_names = stp_features.columns\n",
    "stp_class_labels = np.array(datas['data_type'])\n",
    "\n",
    "X_data = datas.iloc[:,:-1]\n",
    "y_label = datas.iloc[:,-1]\n",
    "\n",
    "# Data Normalization\n",
    "ss = StandardScaler().fit(X_data)\n",
    "X = ss.transform(X_data)\n",
    "le = LabelEncoder()\n",
    "le.fit(y_label)\n",
    "y = le.transform(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for CV, KFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# plots 10-fold with darkred and red\n",
    "from sklearn.metrics import accuracy_score, auc, average_precision_score, confusion_matrix, roc_curve, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cv_lr = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "y_real_lr = []\n",
    "y_proba_lr = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for train_lr, test_lr in cv_lr.split(X, y):\n",
    "    probas_lr = LogisticRegression().fit(X[train_lr], y[train_lr]).predict_proba(X[test_lr])\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_lr, recall_lr, _ = precision_recall_curve(y[test_lr], probas_lr[:, 1])\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    plt.plot(recall_lr, precision_lr, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_lr], probas_lr[:, 1])))\n",
    "        \n",
    "    y_real_lr.append(y[test_lr])\n",
    "    y_proba_lr.append(probas_lr[:, 1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_lr = np.concatenate(y_real_lr)\n",
    "y_proba_lr = np.concatenate(y_proba_lr)\n",
    "    \n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y_real_lr, y_proba_lr)\n",
    "\n",
    "#plt.plot(recall_lr, precision_lr, color='red',\n",
    "#            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_lr, y_proba_lr)),\n",
    "#            lw=2, alpha=0.8)\n",
    "plt.plot(recall_lr, precision_lr,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_lr, y_proba_lr)),\n",
    "            lw=2, alpha=0.8)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Logistic Regression PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dt = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "y_real_dt = []\n",
    "y_proba_dt = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for train_dt, test_dt in cv_dt.split(X, y):\n",
    "    probas_dt = DecisionTreeClassifier(max_depth=4).fit(X[train_dt], y[train_dt]).predict_proba(X[test_dt])\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_dt, recall_dt, _ = precision_recall_curve(y[test_dt], probas_dt[:, 1])\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    #plt.plot(recall_dt, precision_dt, lw=1, alpha=0.3, color='lightgreen',\n",
    "    #        label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_dt], probas_dt[:, 1])))\n",
    "    plt.plot(recall_dt, precision_dt, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_dt], probas_dt[:, 1])))\n",
    "        \n",
    "    y_real_dt.append(y[test_dt])\n",
    "    y_proba_dt.append(probas_dt[:, 1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_dt = np.concatenate(y_real_dt)\n",
    "y_proba_dt = np.concatenate(y_proba_dt)\n",
    "    \n",
    "precision_dt, recall_dt, _ = precision_recall_curve(y_real_dt, y_proba_dt)\n",
    "\n",
    "plt.plot(recall_dt, precision_dt,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_dt, y_proba_dt)),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Decision Tree PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "cv_rf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "y_real_rf = []\n",
    "y_proba_rf = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for train_rf, test_rf in cv_rf.split(X, y):\n",
    "    probas_rf = RandomForestClassifier().fit(X[train_rf], y[train_rf]).predict_proba(X[test_rf])\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_rf, recall_rf, _ = precision_recall_curve(y[test_rf], probas_rf[:, 1])\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    #plt.plot(recall_rf, precision_rf, lw=1, alpha=0.3, color='goldenrod',\n",
    "    #        label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_rf], probas_rf[:, 1])))\n",
    "    plt.plot(recall_rf, precision_rf, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_rf], probas_rf[:, 1])))\n",
    "        \n",
    "    y_real_rf.append(y[test_rf])\n",
    "    y_proba_rf.append(probas_rf[:, 1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_rf = np.concatenate(y_real_rf)\n",
    "y_proba_rf = np.concatenate(y_proba_rf)\n",
    "    \n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_real_rf, y_proba_rf)\n",
    "\n",
    "#plt.plot(recall_rf, precision_rf, color='gold',\n",
    "#            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_rf, y_proba_rf)),\n",
    "#            lw=2, alpha=.8)\n",
    "plt.plot(recall_rf, precision_rf,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_rf, y_proba_rf)),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Random Forest PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with Hyperparamters Tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_rft = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "y_real_rft = []\n",
    "y_proba_rft = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for train_rft, test_rft in cv_rft.split(X, y):\n",
    "    probas_rft = RandomForestClassifier(n_estimators=200, max_features='auto').fit(X[train_rft], y[train_rft]).predict_proba(X[test_rft])\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_rft, recall_rft, _ = precision_recall_curve(y[test_rft], probas_rft[:, 1])\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    #plt.plot(recall_rft, precision_rft, lw=1, alpha=0.3, color='moccasin',\n",
    "    #        label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_rft], probas_rft[:, 1])))\n",
    "    plt.plot(recall_rft, precision_rft, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_rft], probas_rft[:, 1])))\n",
    "                \n",
    "    y_real_rft.append(y[test_rft])\n",
    "    y_proba_rft.append(probas_rft[:, 1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_rft = np.concatenate(y_real_rft)\n",
    "y_proba_rft = np.concatenate(y_proba_rft)\n",
    "    \n",
    "precision_rft, recall_rft, _ = precision_recall_curve(y_real_rft, y_proba_rft)\n",
    "\n",
    "#plt.plot(recall_rft, precision_rft, color='orange',\n",
    "#            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_rft, y_proba_rft)),\n",
    "#            lw=2, alpha=.8)\n",
    "plt.plot(recall_rft, precision_rft,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_rft, y_proba_rft)),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "#plt.xlim([-0.05, 1.05])\n",
    "#plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Random Forest with Hyperparameter Tuning PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "cv_svm = KFold(n_splits=10,shuffle=True)\n",
    "y_real_svm = []\n",
    "y_proba_svm = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for train_svm, test_svm in cv_svm.split(X, y):\n",
    "    probas_svm = SVC(probability=True).fit(X[train_svm], y[train_svm]).predict_proba(X[test_svm])\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_svm, recall_svm, _ = precision_recall_curve(y[test_svm], probas_svm[:, 1])\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    #plt.plot(recall_svm, precision_svm, lw=1, alpha=0.3, color='darkcyan',\n",
    "    #        label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_svm], probas_svm[:, 1])))\n",
    "    plt.plot(recall_svm, precision_svm, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_svm], probas_svm[:, 1])))\n",
    "            \n",
    "    y_real_svm.append(y[test_svm])\n",
    "    y_proba_svm.append(probas_svm[:, 1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_svm = np.concatenate(y_real_svm)\n",
    "y_proba_svm = np.concatenate(y_proba_svm)\n",
    "    \n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_real_svm, y_proba_svm)\n",
    "\n",
    "#plt.plot(recall_svm, precision_svm, color='cyan',\n",
    "#            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_svm, y_proba_svm)),\n",
    "#            lw=2, alpha=.8)\n",
    "plt.plot(recall_svm, precision_svm,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_svm, y_proba_svm)),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Support Vector Machine PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cv_KNN = KFold(n_splits=10,shuffle=True)\n",
    "y_real_KNN = []\n",
    "y_proba_KNN = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for train_KNN, test_KNN in cv_KNN.split(X, y):\n",
    "    probas_KNN = KNeighborsClassifier(n_neighbors=4).fit(X[train_KNN], y[train_KNN]).predict_proba(X[test_KNN])\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_KNN, recall_KNN, _ = precision_recall_curve(y[test_KNN], probas_KNN[:, 1])\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    #plt.plot(recall_KNN, precision_KNN, lw=1, alpha=0.3, color='magenta',\n",
    "    #        label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_KNN], probas_KNN[:, 1])))\n",
    "    plt.plot(recall_KNN, precision_KNN, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_KNN], probas_KNN[:, 1])))\n",
    "    \n",
    "    y_real_KNN.append(y[test_KNN])\n",
    "    y_proba_KNN.append(probas_KNN[:, 1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_KNN = np.concatenate(y_real_KNN)\n",
    "y_proba_KNN = np.concatenate(y_proba_KNN)\n",
    "    \n",
    "precision_KNN, recall_KNN, _ = precision_recall_curve(y_real_KNN, y_proba_KNN)\n",
    "\n",
    "plt.plot(recall_KNN, precision_KNN,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_KNN, y_proba_KNN)),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('K-nearest Neighbors PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# define k-fold cross validation\n",
    "KF_dnn = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "y_real_dnn = []\n",
    "y_proba_dnn = []\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "i = 0\n",
    "for i, (train_dnn, test_dnn) in enumerate(KF_dnn.split(X, y)):\n",
    "    #create model\n",
    "    model_dnn = Sequential()\n",
    "    model_dnn.add(Dense(12, input_dim=79, activation='relu'))\n",
    "    model_dnn.add(Dense(8, activation='relu'))\n",
    "    model_dnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #compile & fit\n",
    "    model_dnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model_dnn.fit(X[train_dnn],y[train_dnn], epochs=100, batch_size=10, verbose=0)\n",
    "                  \n",
    "    probas_dnn = model_dnn.predict_proba(X[test_dnn]).ravel()\n",
    "    # Compute ROC curve and area the curve\n",
    "    precision_dnn, recall_dnn, _ = precision_recall_curve(y[test_dnn], probas_dnn)\n",
    "        \n",
    "    # Plotting each individual PR Curve\n",
    "    #plt.plot(recall_dnn, precision_dnn, lw=1, alpha=0.3, color='royalblue',\n",
    "    #        label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_dnn], probas_dnn)))\n",
    "    plt.plot(recall_dnn, precision_dnn, lw=1, alpha=0.3,\n",
    "            label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y[test_dnn], probas_dnn)))\n",
    "        \n",
    "    y_real_dnn.append(y[test_dnn])\n",
    "    y_proba_dnn.append(probas_dnn)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "y_real_dnn = np.concatenate(y_real_dnn)\n",
    "y_proba_dnn = np.concatenate(y_proba_dnn)\n",
    "    \n",
    "precision_dnn, recall_dnn, _ = precision_recall_curve(y_real_dnn, y_proba_dnn)\n",
    "\n",
    "#plt.plot(recall_dnn, precision_dnn, color='blue',\n",
    "#            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_dnn, y_proba_dnn)),\n",
    "#            lw=2, alpha=.8)\n",
    "plt.plot(recall_dnn, precision_dnn,\n",
    "            label=r'Mean PR (AUC = %0.2f)' % (average_precision_score(y_real_dnn, y_proba_dnn)),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Deep Neural Network PR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots all models in a single figure\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "#fig, ax = plt.subplots(1)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.plot(recall_lr, precision_lr, color='red', label=r'Mean LR PR (AUC=%0.2f)'%(average_precision_score(y_real_lr, y_proba_lr)))\n",
    "plt.plot(recall_dt, precision_dt, color='green', label=r'Mean DT PR (AUC=%0.2f)'%(average_precision_score(y_real_dt, y_proba_dt)))\n",
    "plt.plot(recall_rf, precision_rf, color='gold', label=r'Mean RF PR (AUC=%0.2f)'%(average_precision_score(y_real_rf, y_proba_rf)))\n",
    "plt.plot(recall_rft, precision_rft, color='orange', label=r'Mean RFT PR (AUC=%0.2f)'%(average_precision_score(y_real_rft, y_proba_rft)))\n",
    "plt.plot(recall_svm, precision_svm, color='cyan', label=r'Mean SVM PR (AUC=%0.2f)'%(average_precision_score(y_real_svm, y_proba_svm)))\n",
    "plt.plot(recall_KNN, precision_KNN, color='darkmagenta', label=r'Mean KNN PR (AUC=%0.2f)'%(average_precision_score(y_real_KNN, y_proba_KNN)))\n",
    "plt.plot(recall_dnn, precision_dnn, color='blue', label=r'Mean DNN PR (AUC=%0.2f)'%(average_precision_score(y_real_dnn, y_proba_dnn)))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Mean PR Curve for All Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
